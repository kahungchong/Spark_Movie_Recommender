{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "conf = SparkConf().setAppName('Elephas_App').setMaster('local[8]')\n",
    "try:\n",
    "    sc.stop()\n",
    "except:\n",
    "    pass\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Embedding, Reshape, Activation, Input, Dense, Flatten, Dropout\n",
    "from keras.layers.merge import Dot, multiply, concatenate\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import skipgrams\n",
    "from keras import losses\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(max_work, max_user):\n",
    "    dim_embedddings = 30\n",
    "    bias = 1\n",
    "    # inputs\n",
    "    w_inputs = Input(shape=(1,), dtype='int32')\n",
    "    w = Embedding(max_work+1, dim_embedddings, name=\"work\")(w_inputs)\n",
    "    w_bis = Embedding(max_work + 1, bias, name=\"workbias\")(w_inputs)\n",
    "\n",
    "    # context\n",
    "    u_inputs = Input(shape=(1,), dtype='int32')\n",
    "    u = Embedding(max_user+1, dim_embedddings, name=\"user\")(u_inputs)\n",
    "    u_bis = Embedding(max_user + 1, bias, name=\"userbias\")(u_inputs)\n",
    "    \n",
    "    #genre_inputs = Input(shape=(20,1,), dtype='int32')\n",
    "    #genre = Embedding(21,dim_embedddings, name=\"genre\")(genre_inputs)\n",
    "    \n",
    "    o = multiply([w, u])\n",
    "    o = Dropout(0.5)(o)\n",
    "    o = concatenate([o, u_bis, w_bis])\n",
    "    o = Flatten()(o)\n",
    "    o = Dense(10, activation=\"relu\")(o)\n",
    "    o = Dense(1)(o)\n",
    "\n",
    "    rec_model = Model(inputs=[w_inputs, u_inputs], outputs=o)\n",
    "    #rec_model.summary()\n",
    "    rec_model.compile(loss = losses.mean_squared_error, optimizer='adam', metrics=[metrics.mae])\n",
    "\n",
    "    return rec_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres=[\"Action\",\"Adventure\",\"Animation\",\"Children\",\"Comedy\",\"Crime\",\"Documentary\",\"Drama\",\\\n",
    "            \"Fantasy\",\"Film-Noir\",\"Horror\",\"Musical\",\"Mystery\",\"Romance\",\"Sci-Fi\",\"Thriller\",\"War\",\"Western\",\"IMAX\",\"(no genres listed)\"]\n",
    "genres_index = {}\n",
    "for i, gen in enumerate(genres):\n",
    "    genres_index[gen]=i\n",
    "\n",
    "def genres_to_array(g):\n",
    "    genre_array = np.array([0]*len(genres))\n",
    "    for i in g.split(\"|\"):\n",
    "        genre_array[genres_index[i]]=1\n",
    "    return genre_array\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path):\n",
    "    genre = pd.read_csv(path+\"/movies.csv\")\n",
    "    genre[\"genres\"] = genre[\"genres\"].apply(genres_to_array)\n",
    "    genre = genre[[\"movieId\",\"genres\"]]\n",
    "\n",
    "    rating = pd.read_csv(path+\"/ratings.csv\")\n",
    "    \n",
    "    data = pd.merge(genre, rating, how='right', on='movieId')\n",
    "    \n",
    "    data[\"genres\"] = data[\"genres\"].apply(lambda g:g if isinstance(g, list) else [0]*len(genres))\n",
    "    percentil_80 = np.percentile(data[\"timestamp\"], 80)\n",
    "    \n",
    "\n",
    "    print(percentil_80)\n",
    "\n",
    "    print(np.mean(data[\"timestamp\"]<percentil_80))\n",
    "\n",
    "    print(np.mean(data[\"timestamp\"]>percentil_80))\n",
    "\n",
    "    cols = [\"userId\", \"movieId\", \"genres\", \"rating\"]\n",
    "\n",
    "    train = data[data.timestamp<percentil_80][cols]\n",
    "\n",
    "    print(train.shape)\n",
    "\n",
    "    test = data[data.timestamp>=percentil_80][cols]\n",
    "\n",
    "    print(test.shape)\n",
    "\n",
    "    max_user = max(data[\"userId\"].tolist() )\n",
    "    max_work = max(data[\"movieId\"].tolist() )\n",
    "\n",
    "\n",
    "    return train, test, max_user, max_work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_array(series):\n",
    "    return np.array([[element] for element in series])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "975768738.0\n",
      "0.7999968006686603\n",
      "0.19999920016716508\n",
      "(800164, 4)\n",
      "(200045, 4)\n"
     ]
    }
   ],
   "source": [
    "train, test, max_user, max_work = get_data(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(max_work, max_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "work (Embedding)                (None, 1, 30)        118590      input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "user (Embedding)                (None, 1, 30)        181230      input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 1, 30)        0           work[0][0]                       \n",
      "                                                                 user[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1, 30)        0           multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "userbias (Embedding)            (None, 1, 1)         6041        input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "workbias (Embedding)            (None, 1, 1)         3953        input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 1, 32)        0           dropout_4[0][0]                  \n",
      "                                                                 userbias[0][0]                   \n",
      "                                                                 workbias[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 32)           0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 10)           330         flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            11          dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 310,155\n",
      "Trainable params: 310,155\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [get_array(train[\"movieId\"]), get_array(train[\"userId\"])]\n",
    "y_train = get_array(train[\"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING\n"
     ]
    }
   ],
   "source": [
    "from elephas.utils.rdd_utils import to_simple_rdd\n",
    "rdd = to_simple_rdd(sc, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from elephas.spark_model import SparkModel\n",
    "\n",
    "#spark_model = SparkModel(model, frequency='epoch', mode='asynchronous')\n",
    "#spark_model.fit(rdd, epochs=20, batch_size=32, verbose=0, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/ChongKaHung/anaconda3/envs/spark/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ChongKaHung/anaconda3/envs/spark/lib/python3.6/site-packages/ipykernel/__main__.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 640131 samples, validate on 160033 samples\n",
      "Epoch 1/10\n",
      "640131/640131 [==============================] - 120s 188us/step - loss: 1.1855 - mean_absolute_error: 0.8178 - val_loss: 1.4551 - val_mean_absolute_error: 1.0067\n",
      "Epoch 2/10\n",
      "640131/640131 [==============================] - 126s 196us/step - loss: 0.7780 - mean_absolute_error: 0.6930 - val_loss: 1.3449 - val_mean_absolute_error: 0.9620\n",
      "Epoch 3/10\n",
      "640131/640131 [==============================] - 130s 203us/step - loss: 0.7369 - mean_absolute_error: 0.6720 - val_loss: 1.3123 - val_mean_absolute_error: 0.9462\n",
      "Epoch 4/10\n",
      "640131/640131 [==============================] - 125s 196us/step - loss: 0.7113 - mean_absolute_error: 0.6590 - val_loss: 1.2806 - val_mean_absolute_error: 0.9326\n",
      "Epoch 5/10\n",
      "640131/640131 [==============================] - 121s 188us/step - loss: 0.6932 - mean_absolute_error: 0.6492 - val_loss: 1.3072 - val_mean_absolute_error: 0.9441\n",
      "Epoch 6/10\n",
      "640131/640131 [==============================] - 128s 200us/step - loss: 0.6809 - mean_absolute_error: 0.6428 - val_loss: 1.2874 - val_mean_absolute_error: 0.9348\n",
      "Epoch 7/10\n",
      "640131/640131 [==============================] - 129s 201us/step - loss: 0.6715 - mean_absolute_error: 0.6377 - val_loss: 1.2778 - val_mean_absolute_error: 0.9296\n",
      "Epoch 8/10\n",
      "640131/640131 [==============================] - 143s 224us/step - loss: 0.6617 - mean_absolute_error: 0.6329 - val_loss: 1.2884 - val_mean_absolute_error: 0.9350\n",
      "Epoch 9/10\n",
      "640131/640131 [==============================] - 141s 221us/step - loss: 0.6547 - mean_absolute_error: 0.6294 - val_loss: 1.3007 - val_mean_absolute_error: 0.9397\n",
      "Epoch 10/10\n",
      "640131/640131 [==============================] - 146s 229us/step - loss: 0.6506 - mean_absolute_error: 0.6275 - val_loss: 1.2627 - val_mean_absolute_error: 0.9231\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, nb_epoch=10,\n",
    "                    validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict([get_array(test[\"movieId\"]), get_array(test[\"userId\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_performance = mean_absolute_error(test[\"rating\"], predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.811744453944615"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, HTML, display\n",
    "import tmdbsimple as tmdb\n",
    "tmdb.API_KEY = '31362d194b7b8e33df9fdbfa6e138b49'\n",
    "def get_resc_to_user(the_id,num=10):\n",
    "    rating = pd.read_csv(\"../data/ratings.csv\")\n",
    "    rating = rating[rating[\"userId\"]!=the_id]\n",
    "    movie = rating[[\"movieId\"]].reset_index(drop=True).drop_duplicates()\n",
    "    score = pd.DataFrame(model.predict([[the_id]*len(movie),movie]))\n",
    "    movie[\"score\"]=score\n",
    "    return movie.sort_values(by=['score'],ascending=False).head(num)\n",
    "\n",
    "def display_resc_to_user(the_id,num=10):\n",
    "    recs = get_resc_to_user(the_id,num)\n",
    "    display(HTML(\"<h2>Get recommended movies for user id %s</h2>\" % the_id))\n",
    "    display(HTML(\"<h4>Recommended movies:</h4>\"))\n",
    "    rec_html = \"<table border=0>\"\n",
    "    i = 0\n",
    "    for i,rec in recs.iterrows():\n",
    "        movie_id = int(rec.movieId)\n",
    "        img_url = get_poster_url(movie_id)\n",
    "        score = rec.score\n",
    "        title = get_movie_title(movie_id)\n",
    "        rec_html += \"<td><h5>%s</h5><img src=%s width=150></img></td><td><h5>%2.3f</h5></td>\" % (title,img_url, score)\n",
    "        i += 1\n",
    "        if i % 5 == 0:\n",
    "            rec_html += \"</tr><tr>\"\n",
    "    rec_html += \"</tr></table>\"\n",
    "    display(HTML(rec_html))\n",
    "\n",
    "def get_movie_title(movie_id):\n",
    "    movie = pd.read_csv(\"../data/movies.csv\")\n",
    "    return movie[movie[\"movieId\"]==movie_id][[\"title\"]].values[0][0]\n",
    "\n",
    "def get_poster_url(movie_id):\n",
    "    links = pd.read_csv(\"../data/links.csv\")\n",
    "    id = int(links[links[\"movieId\"]==movie_id][\"tmdbId\"])\n",
    "    IMAGE_URL = 'https://image.tmdb.org/t/p/w500'\n",
    "    try:\n",
    "        movie = tmdb.Movies(id).info()\n",
    "        poster_url = IMAGE_URL + movie['poster_path'] if 'poster_path' in movie and movie['poster_path'] is not None else \"\"\n",
    "        return poster_url\n",
    "    except:\n",
    "        return \"KEY_ERR\"\n",
    "    return \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Get recommended movies for user id 1</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h4>Recommended movies:</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=0><td><h5>Cocoon (1985)</h5><img src=https://image.tmdb.org/t/p/w500/foIhEPQoqDctfwsHmmYwbNz5A2g.jpg width=150></img></td><td><h5>4.950</h5></td><td><h5>Universal Soldier (1992)</h5><img src=https://image.tmdb.org/t/p/w500/3GjUDlGF58VAFjRdR0mVoxNAZQ6.jpg width=150></img></td><td><h5>4.933</h5></td><td><h5>Firm, The (1993)</h5><img src=https://image.tmdb.org/t/p/w500/2yKjIGzQF5mhG634MwG6oBTH1ce.jpg width=150></img></td><td><h5>4.898</h5></td></tr><tr><td><h5>Secret Garden, The (1993)</h5><img src=https://image.tmdb.org/t/p/w500/u0viU22u7ABDESyoPMcvM2jr4hJ.jpg width=150></img></td><td><h5>4.883</h5></td><td><h5>Mr. Saturday Night (1992)</h5><img src=https://image.tmdb.org/t/p/w500/3rvZsOWshndy8t3YK0tnkd6r9wT.jpg width=150></img></td><td><h5>4.851</h5></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_resc_to_user(1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:spark]",
   "language": "python",
   "name": "conda-env-spark-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
